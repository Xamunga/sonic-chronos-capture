
import { toast } from "sonner";
import { logSystem } from '@/utils/logSystem';

// NOVO: Debounce utility para otimiza√ß√£o de performance
function debounce<T extends (...args: any[]) => any>(
  func: T,
  wait: number
): (...args: Parameters<T>) => void {
  let timeout: NodeJS.Timeout;
  return (...args: Parameters<T>) => {
    clearTimeout(timeout);
    timeout = setTimeout(() => func(...args), wait);
  };
}

// Interface para funcionalidades de √°udio nativas no Electron
export class ElectronAudioService {
  private mediaRecorder: MediaRecorder | null = null;
  private audioChunks: Blob[] = [];
  private isRecording = false;
  private isPaused = false;
  private outputPath = '';
  private inputDevice = 'default';
  private outputFormat = 'wav';
  private mp3Bitrate = 320;
  private sampleRate = 44100;
  private splitEnabled = false;
  private splitIntervalMinutes = 5;
  private dateFolderEnabled = false;
  private dateFolderFormat = 'dd-mm';
  private fileNameFormat = 'timestamp';
  private recordingStartTime = 0;
  private currentSplitNumber = 1;
  private audioContext: AudioContext | null = null;
  private analyser: AnalyserNode | null = null;
  private noiseGateNode: AudioWorkletNode | null = null;
  private volumeCallbacks: ((left: number, right: number, peak: boolean) => void)[] = [];
  private spectrumCallbacks: ((data: number[]) => void)[] = [];
  private hasSignal = false;
  
  // NOVO: Sistema de monitoramento independente
  private monitoringStream: MediaStream | null = null;
  private monitoringContext: AudioContext | null = null;
  private monitoringAnalyser: AnalyserNode | null = null;
  
  // Configura√ß√µes do Noise Gate
  private noiseSuppressionEnabled = false;
  private noiseThreshold = -35; // dB
  private noiseGateAttack = 50; // ms
  private noiseGateRelease = 200; // ms

  constructor() {
    this.loadSettings();
    // N√ÉO inicializar monitoramento automaticamente
    console.log('üéõÔ∏è ElectronAudioService inicializado (monitoramento sob demanda)');
  }

  private loadSettings() {
    try {
      const settings = localStorage.getItem('audioSettings');
      if (settings) {
        const parsed = JSON.parse(settings);
        
        // Validar tipos antes de usar
        this.outputFormat = typeof parsed.outputFormat === 'string' ? parsed.outputFormat : 'wav';
        this.mp3Bitrate = typeof parsed.mp3Bitrate === 'number' ? parsed.mp3Bitrate : 320;
        this.splitEnabled = typeof parsed.splitEnabled === 'boolean' ? parsed.splitEnabled : false;
        this.splitIntervalMinutes = typeof parsed.splitIntervalMinutes === 'number' ? parsed.splitIntervalMinutes : 5;
        this.dateFolderEnabled = typeof parsed.dateFolderEnabled === 'boolean' ? parsed.dateFolderEnabled : false;
        this.dateFolderFormat = typeof parsed.dateFolderFormat === 'string' ? parsed.dateFolderFormat : 'dd-mm';
        this.fileNameFormat = typeof parsed.fileNameFormat === 'string' ? parsed.fileNameFormat : 'timestamp';
        this.inputDevice = typeof parsed.inputDevice === 'string' ? parsed.inputDevice : 'default';
        this.noiseSuppressionEnabled = typeof parsed.noiseSuppressionEnabled === 'boolean' ? parsed.noiseSuppressionEnabled : false;
        this.noiseThreshold = typeof parsed.noiseThreshold === 'number' ? parsed.noiseThreshold : -35;
        this.noiseGateAttack = typeof parsed.noiseGateAttack === 'number' ? parsed.noiseGateAttack : 50;
        this.noiseGateRelease = typeof parsed.noiseGateRelease === 'number' ? parsed.noiseGateRelease : 200;
        
        console.log('‚úÖ Configura√ß√µes carregadas com valida√ß√£o');
      }
    } catch (error) {
      console.error('‚ùå Erro ao carregar configura√ß√µes, usando padr√µes:', error);
      logSystem.error(`Erro ao carregar configura√ß√µes: ${error}`, 'Settings');
      // Usar valores padr√£o em caso de erro
      this.resetToDefaults();
    }
  }

  private resetToDefaults() {
    this.outputFormat = 'wav';
    this.mp3Bitrate = 320;
    this.splitEnabled = false;
    this.splitIntervalMinutes = 5;
    this.dateFolderEnabled = false;
    this.dateFolderFormat = 'dd-mm';
    this.fileNameFormat = 'timestamp';
    this.inputDevice = 'default';
    this.noiseSuppressionEnabled = false;
    this.noiseThreshold = -35;
    this.noiseGateAttack = 50;
    this.noiseGateRelease = 200;
  }

  saveSettings() {
    try {
      const settings = {
        outputFormat: this.outputFormat,
        mp3Bitrate: this.mp3Bitrate,
        splitEnabled: this.splitEnabled,
        splitIntervalMinutes: this.splitIntervalMinutes,
        dateFolderEnabled: this.dateFolderEnabled,
        dateFolderFormat: this.dateFolderFormat,
        fileNameFormat: this.fileNameFormat,
        inputDevice: this.inputDevice, // IMPORTANTE: Incluir inputDevice
        noiseSuppressionEnabled: this.noiseSuppressionEnabled,
        noiseThreshold: this.noiseThreshold,
        noiseGateAttack: this.noiseGateAttack,
        noiseGateRelease: this.noiseGateRelease
      };
      
      localStorage.setItem('audioSettings', JSON.stringify(settings));
      console.log('‚úÖ Configura√ß√µes salvas com sucesso');
      logSystem.info('Configura√ß√µes salvas', 'Settings');
      
    } catch (error) {
      console.error('‚ùå Erro ao salvar configura√ß√µes:', error);
      logSystem.error(`Erro ao salvar configura√ß√µes: ${error}`, 'Settings');
      toast.error('Erro ao salvar configura√ß√µes');
    }
  }

  // M√âTODO CORRIGIDO: requestMicrophonePermission
  async requestMicrophonePermission(): Promise<boolean> {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: this.noiseSuppressionEnabled,
          noiseSuppression: this.noiseSuppressionEnabled,
          autoGainControl: this.noiseSuppressionEnabled,
          deviceId: this.inputDevice !== 'default' ? { exact: this.inputDevice } : undefined,
          channelCount: 1, // FOR√áAR MONO
          sampleRate: 44100
        }
      });
      
      // Parar stream de teste
      stream.getTracks().forEach(track => track.stop());
      
      console.log('‚úÖ Permiss√£o de microfone concedida');
      console.log(`üéõÔ∏è Configura√ß√µes aplicadas: supress√£o=${this.noiseSuppressionEnabled}`);
      logSystem.info(`Permiss√£o de microfone concedida com supress√£o=${this.noiseSuppressionEnabled}`, 'Audio');
      
      return true;
    } catch (error) {
      console.error('‚ùå Erro ao solicitar permiss√£o:', error);
      logSystem.error(`Erro ao solicitar permiss√£o de microfone: ${error}`, 'Audio');
      toast.error('Erro ao acessar o microfone. Verifique as permiss√µes.');
      return false;
    }
  }

  async startRecording(outputPath: string): Promise<boolean> {
    try {
      if (this.isRecording) {
        toast.warning('Grava√ß√£o j√° est√° em andamento');
        return false;
      }

      // Inicializar monitoramento apenas ao iniciar grava√ß√£o
      if (!this.monitoringContext) {
        await this.initializeMonitoring();
      }

      // Carregar configura√ß√µes mais recentes antes de iniciar
      this.loadSettings();
      
      // Log para aba de logs
      logSystem.info('Iniciando grava√ß√£o', 'Recording');
      logSystem.info(`Dispositivo: ${this.inputDevice || 'padr√£o'}`, 'Audio');

      this.recordingStartTime = Date.now();
      this.currentSplitNumber = 1;

      // Criar pasta com data se habilitado
      let finalOutputPath = outputPath;
      if (this.dateFolderEnabled) {
        const dateFolder = this.formatDateFolder();
        // Remover barras duplas e normalizar o path
        const normalizedPath = outputPath.replace(/[\\\/]+$/, '');
        finalOutputPath = `${normalizedPath}\\${dateFolder}`;
        
        console.log(`Pasta por data habilitada. Pasta base: ${normalizedPath}`);
        console.log(`Formato de data: ${this.dateFolderFormat}`);
        console.log(`Pasta de data criada: ${dateFolder}`);
        console.log(`Caminho final: ${finalOutputPath}`);
        
        await this.ensureDirectoryExists(finalOutputPath);
      } else {
        console.log(`Pasta por data desabilitada. Usando pasta base: ${outputPath}`);
        await this.ensureDirectoryExists(outputPath);
        finalOutputPath = outputPath;
      }

      this.outputPath = finalOutputPath;
      console.log(`Grava√ß√£o ser√° salva em: ${this.outputPath}`);

      // Validar dispositivo antes de usar
      const isValidDevice = await this.validateAudioDevice(this.inputDevice);
      if (!isValidDevice) {
        console.warn('‚ö†Ô∏è Dispositivo inv√°lido, usando padr√£o');
        this.inputDevice = 'default';
      }

      const hasPermission = await this.requestMicrophonePermission();
      if (!hasPermission) return false;

      console.log('üé§ INICIANDO GRAVA√á√ÉO');

      // Usar mesmo stream do monitoramento para grava√ß√£o
      const constraints: MediaStreamConstraints = {
        audio: {
          deviceId: this.inputDevice ? { exact: this.inputDevice } : undefined,
          echoCancellation: this.noiseSuppressionEnabled,
          noiseSuppression: this.noiseSuppressionEnabled,
          autoGainControl: this.noiseSuppressionEnabled,
          channelCount: 1, // FOR√áAR MONO para evitar mixagem
          sampleRate: 44100
        }
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);

      // Configurar an√°lise de √°udio DURANTE A GRAVA√á√ÉO
      this.setupAudioAnalysis(stream);
      
      // CR√çTICO: Iniciar an√°lise independente para VU Meters sempre ativa
      this.forceAudioAnalysisStart();

      // Usar formato de alta qualidade sem compress√£o desnecess√°ria
      let mimeType = 'audio/webm;codecs=opus';
      
      // Verificar suporte e usar melhor op√ß√£o dispon√≠vel
      if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
        mimeType = 'audio/webm;codecs=opus';
      } else if (MediaRecorder.isTypeSupported('audio/webm')) {
        mimeType = 'audio/webm';
      } else {
        mimeType = 'audio/mp4';
      }
      
      console.log(`Usando MIME type: ${mimeType} para formato: ${this.outputFormat}`);
      
      const mediaRecorderOptions: MediaRecorderOptions = {
        mimeType: mimeType,
        audioBitsPerSecond: this.mp3Bitrate * 1000
      };
      
      this.mediaRecorder = new MediaRecorder(stream, mediaRecorderOptions);

      this.audioChunks = [];
      this.outputPath = finalOutputPath;

      this.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          this.audioChunks.push(event.data);
        }
      };

      this.mediaRecorder.onstop = () => {
        this.saveRecording();
      };

      this.mediaRecorder.start(1000); // Capturar dados a cada segundo
      this.isRecording = true;
      this.isPaused = false;
      
      console.log('üìà VU Callbacks registrados:', this.volumeCallbacks.length);
      console.log('üìä Spectrum Callbacks registrados:', this.spectrumCallbacks.length);

      // Inicializar sinal de √°udio ap√≥s um pequeno delay
      setTimeout(() => {
        this.forceAudioAnalysisStart();
        console.log('üéµ An√°lise de √°udio iniciada - VU Meters e Spectrum devem estar funcionando');
      }, 500);

      // Configurar split autom√°tico se habilitado
      if (this.splitEnabled) {
        this.scheduleSplit();
      }

      console.log('üé¨ Grava√ß√£o iniciada com sucesso');
      logSystem.info(`Formato: MP3, ${this.sampleRate}Hz, ${this.mp3Bitrate}kbps`, 'Recording');
      toast.success('Grava√ß√£o iniciada com sucesso');
      return true;

    } catch (error) {
      console.error('‚ùå Erro ao iniciar grava√ß√£o:', error);
      logSystem.error(`Erro ao iniciar grava√ß√£o: ${error.message}`, 'Recording');
      toast.error('Erro ao iniciar grava√ß√£o');
      return false;
    }
  }

  async stopRecording(): Promise<void> {
    try {
      if (this.mediaRecorder && this.isRecording) {
        this.mediaRecorder.stop();
        this.mediaRecorder.stream.getTracks().forEach(track => track.stop());
        this.isRecording = false;
        this.isPaused = false;
        this.currentSplitNumber = 1;
        
        // Limpar contexto de √°udio
        this.cleanupAudioAnalysis();
        
        // IMPORTANTE: Suspender monitoramento para economizar recursos
        if (this.monitoringContext && this.monitoringContext.state === 'running') {
          await this.monitoringContext.suspend();
          console.log('‚è∏Ô∏è Monitoramento suspenso para economizar recursos');
        }
        
        // Zerar VU meters
        this.volumeCallbacks.forEach(callback => {
          try {
            callback(-60, -60, false);
          } catch (error) {
            console.error('‚ùå Erro ao zerar VU:', error);
          }
        });
        
        // Zerar spectrum analyzer
        this.spectrumCallbacks.forEach(callback => {
          try {
            callback(Array(32).fill(0));
          } catch (error) {
            console.error('‚ùå Erro ao zerar spectrum:', error);
          }
        });
        
        console.log('‚èπÔ∏è Grava√ß√£o finalizada com sucesso');
        logSystem.info('Grava√ß√£o finalizada', 'Recording');
        toast.success('Grava√ß√£o finalizada');
      }
    } catch (error) {
      console.error('‚ùå Erro ao parar grava√ß√£o:', error);
    }
  }

  // M√âTODO CORRIGIDO: pauseRecording
  pauseRecording(): void {
    if (this.mediaRecorder && this.isRecording) {
      if (this.mediaRecorder.state === 'recording') {
        this.mediaRecorder.pause();
        this.isPaused = true;
        
        // N√ÉO parar monitoramento durante pausa
        console.log('‚è∏Ô∏è Grava√ß√£o pausada (monitoramento continua)');
        logSystem.info('Grava√ß√£o pausada', 'Recording');
        toast.info('Grava√ß√£o pausada');
      } else if (this.mediaRecorder.state === 'paused') {
        this.mediaRecorder.resume();
        this.isPaused = false;
        console.log('‚ñ∂Ô∏è Grava√ß√£o retomada');
        logSystem.info('Grava√ß√£o retomada', 'Recording');
        toast.info('Grava√ß√£o retomada');
      }
    }
  }

  private async saveRecording(): Promise<void> {
    try {
      const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
      const arrayBuffer = await audioBlob.arrayBuffer();
      const uint8Array = new Uint8Array(arrayBuffer);

      // Se estiver no Electron, usar a API nativa para salvar
      if (window.electronAPI) {
        const filename = this.formatFileName();

        // Garantir que estamos usando o outputPath correto (j√° inclui a subpasta se habilitada)
        console.log(`Salvando arquivo em: ${this.outputPath}`);
        console.log(`Nome do arquivo: ${filename}`);
        
        // Normalizar path e garantir que o arquivo seja salvo no diret√≥rio correto
        const normalizedPath = this.outputPath.replace(/[\\\/]+$/, '');
        const fullPath = `${normalizedPath}\\${filename}`;
        
        console.log(`Caminho completo do arquivo: ${fullPath}`);

        try {
          await window.electronAPI.saveAudioFile(fullPath, uint8Array);
          console.log(`‚úÖ Arquivo salvo com sucesso em: ${fullPath}`);
          logSystem.info(`Arquivo salvo: ${filename}`, 'Recording');
          toast.success(`Arquivo salvo: ${filename}`);
        } catch (error) {
          console.error('‚ùå Erro ao salvar via Electron API:', error);
          logSystem.error(`Erro ao salvar arquivo: ${error}`, 'Recording');
          // Fallback para download
          this.downloadAudioFile(audioBlob, filename);
        }
      } else {
        // Fallback para download no navegador
        const extension = this.outputFormat === 'wav' ? 'wav' : 
                         this.outputFormat === 'mp3' ? 'mp3' : 'webm';
        const filename = `gravacao_${Date.now()}.${extension}`;
        this.downloadAudioFile(audioBlob, filename);
      }

    } catch (error) {
      console.error('Erro ao salvar grava√ß√£o:', error);
      toast.error('Erro ao salvar arquivo de √°udio');
    }
  }

  private downloadAudioFile(blob: Blob, filename: string): void {
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = filename;
    a.click();
    URL.revokeObjectURL(url);
    toast.success(`Download iniciado: ${filename}`);
  }

  isCurrentlyRecording(): boolean {
    return this.isRecording;
  }

  getRecordingState(): string {
    if (!this.mediaRecorder) return 'stopped';
    return this.mediaRecorder.state;
  }

  async getAudioDevices(): Promise<MediaDeviceInfo[]> {
    try {
      const devices = await navigator.mediaDevices.enumerateDevices();
      return devices.filter(device => device.kind === 'audioinput');
    } catch (error) {
      console.error('Erro ao obter dispositivos de √°udio:', error);
      return [];
    }
  }

  setInputDevice(deviceId: string): void {
    const oldDevice = this.inputDevice;
    this.inputDevice = deviceId;
    this.saveSettings();
    
    logSystem.info(`Dispositivo alterado: ${oldDevice || 'padr√£o'} ‚Üí ${deviceId}`, 'Audio');
    
    this.restartMonitoring();
    
    console.log(`üé§ Dispositivo alterado para: ${deviceId}`);
  }

  // NOVO: Valida√ß√£o de dispositivos de √°udio
  private async validateAudioDevice(deviceId: string): Promise<boolean> {
    try {
      if (deviceId === 'default') return true;
      
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioInputs = devices.filter(device => device.kind === 'audioinput');
      
      return audioInputs.some(device => device.deviceId === deviceId);
    } catch (error) {
      console.error('‚ùå Erro ao validar dispositivo:', error);
      return false;
    }
  }

  setOutputFormat(format: string): void {
    this.outputFormat = format;
  }

  setSampleRate(rate: number): void {
    this.sampleRate = rate;
  }

  async ensureDirectoryExists(dirPath: string): Promise<void> {
    try {
      console.log(`üîç Verificando diret√≥rio: ${dirPath}`);
      if (window.electronAPI) {
        await window.electronAPI.ensureDirectory(dirPath);
        console.log(`‚úÖ Diret√≥rio criado/verificado: ${dirPath}`);
      } else {
        // No navegador, apenas logar
        console.log('‚ö†Ô∏è Modo navegador - diret√≥rios n√£o podem ser criados automaticamente');
      }
    } catch (error) {
      console.error('‚ùå Erro ao verificar/criar diret√≥rio:', error);
      toast.error(`Erro ao criar pasta: ${dirPath}`);
      throw error;
    }
  }

  getInputDevice(): string {
    return this.inputDevice;
  }

  getOutputFormat(): string {
    return this.outputFormat;
  }

  getSampleRate(): number {
    return this.sampleRate;
  }

  // Configura√ß√µes de split
  setSplitEnabled(enabled: boolean): void {
    this.splitEnabled = enabled;
  }

  setSplitInterval(minutes: number): void {
    this.splitIntervalMinutes = minutes;
  }

  getSplitEnabled(): boolean {
    return this.splitEnabled;
  }

  getSplitInterval(): number {
    return this.splitIntervalMinutes;
  }

  // Configura√ß√µes de pasta por data
  setDateFolderEnabled(enabled: boolean): void {
    this.dateFolderEnabled = enabled;
  }

  setDateFolderFormat(format: string): void {
    this.dateFolderFormat = format;
  }

  getDateFolderEnabled(): boolean {
    return this.dateFolderEnabled;
  }

  getDateFolderFormat(): string {
    return this.dateFolderFormat;
  }

  private formatDateFolder(): string {
    const now = new Date();
    const day = now.getDate().toString().padStart(2, '0');
    const month = (now.getMonth() + 1).toString().padStart(2, '0');
    const year = now.getFullYear().toString();

    switch (this.dateFolderFormat) {
      case 'dd-mm':
        return `${day}-${month}`;
      case 'dd-mm-yyyy':
        return `${day}-${month}-${year}`;
      case 'mm-dd-yyyy':
        return `${month}-${day}-${year}`;
      case 'yyyy-mm-dd':
        return `${year}-${month}-${day}`;
      case 'yyyy/mm/dd':
        return `${year}/${month}/${day}`;
      default:
        return `${day}-${month}`;
    }
  }

  private formatFileName(): string {
    const now = new Date();
    const day = now.getDate().toString().padStart(2, '0');
    const month = (now.getMonth() + 1).toString().padStart(2, '0');
    const year = now.getFullYear().toString();
    const hours = now.getHours().toString().padStart(2, '0');
    const minutes = now.getMinutes().toString().padStart(2, '0');
    const seconds = now.getSeconds().toString().padStart(2, '0');

    const extension = this.outputFormat === 'wav' ? 'wav' : 
                     this.outputFormat === 'mp3' ? 'mp3' : 'webm';

    let baseName: string;
    switch (this.fileNameFormat) {
      case 'hh-mm-ss-seq':
        baseName = `${hours}-${minutes}-${seconds}-${this.currentSplitNumber.toString().padStart(3, '0')}`;
        break;
      case 'dd-mm-hh-mm-ss-seq':
        baseName = `${day}-${month}-${hours}-${minutes}-${seconds}-${this.currentSplitNumber.toString().padStart(3, '0')}`;
        break;
      case 'timestamp':
      default:
        const timestamp = now.toISOString().replace(/[:.]/g, '-').slice(0, 19);
        baseName = this.splitEnabled && this.currentSplitNumber > 1 
          ? `gravacao_${timestamp}_parte${this.currentSplitNumber}`
          : `gravacao_${timestamp}`;
        break;
    }

    return `${baseName}.${extension}`;
  }

  private scheduleSplit(): void {
    setTimeout(() => {
      if (this.isRecording && this.splitEnabled) {
        this.performSplit();
      }
    }, this.splitIntervalMinutes * 60 * 1000);
  }

  private async performSplit(): Promise<void> {
    if (!this.isRecording || !this.mediaRecorder) return;

    try {
      // Parar grava√ß√£o atual
      this.mediaRecorder.stop();
      
      // Aguardar um breve momento para processamento
      await new Promise(resolve => setTimeout(resolve, 500));
      
      // Incrementar n√∫mero da parte
      this.currentSplitNumber++;
      
      // Reiniciar grava√ß√£o com novo arquivo
      this.audioChunks = [];
      const stream = this.mediaRecorder.stream;
      
      // Recriar MediaRecorder
      this.mediaRecorder = new MediaRecorder(stream, {
        mimeType: this.mediaRecorder.mimeType
      });

      this.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          this.audioChunks.push(event.data);
        }
      };

      this.mediaRecorder.onstop = () => {
        this.saveRecording();
      };

      this.mediaRecorder.start(1000);
      
      // Agendar pr√≥ximo split
      this.scheduleSplit();
      
      toast.info(`Iniciando parte ${this.currentSplitNumber} da grava√ß√£o`);
    } catch (error) {
      console.error('Erro ao fazer split:', error);
      toast.error('Erro ao dividir arquivo');
    }
  }

  // An√°lise de √°udio em tempo real
  private setupAudioAnalysis(stream: MediaStream): void {
    try {
      this.audioContext = new AudioContext({ sampleRate: 44100 });
      const source = this.audioContext.createMediaStreamSource(stream);
      
      this.analyser = this.audioContext.createAnalyser();
      this.analyser.fftSize = 2048;
      this.analyser.smoothingTimeConstant = 0.3;
      
      // N√ÉO conectar ao destination para evitar feedback
      source.connect(this.analyser);
      
      console.log('üé§ Contexto de √°udio configurado para an√°lise em tempo real');
      console.log('üìä Configura√ß√µes AudioContext:', {
        sampleRate: this.audioContext.sampleRate,
        fftSize: this.analyser.fftSize,
        frequencyBinCount: this.analyser.frequencyBinCount
      });
      this.startAudioAnalysis();
    } catch (error) {
      console.error('‚ùå Erro ao configurar an√°lise de √°udio:', error);
      logSystem.error(`Erro ao configurar an√°lise de √°udio: ${error}`, 'Audio');
    }
  }

  private createNoiseProcessingChain(audioContext: AudioContext, sourceNode: AudioNode): AudioNode {
    try {
      // Filtro High-Pass para remover ru√≠do de baixa frequ√™ncia
      const highPassFilter = audioContext.createBiquadFilter();
      highPassFilter.type = 'highpass';
      highPassFilter.frequency.setValueAtTime(80, audioContext.currentTime);
      highPassFilter.Q.setValueAtTime(1, audioContext.currentTime);
      
      // Filtro Notch para remover ru√≠do el√©trico de 60Hz
      const notchFilter60Hz = audioContext.createBiquadFilter();
      notchFilter60Hz.type = 'notch';
      notchFilter60Hz.frequency.setValueAtTime(60, audioContext.currentTime);
      notchFilter60Hz.Q.setValueAtTime(10, audioContext.currentTime);
      
      // Filtro Notch para remover ru√≠do el√©trico de 50Hz (Europa)
      const notchFilter50Hz = audioContext.createBiquadFilter();
      notchFilter50Hz.type = 'notch';
      notchFilter50Hz.frequency.setValueAtTime(50, audioContext.currentTime);
      notchFilter50Hz.Q.setValueAtTime(10, audioContext.currentTime);
      
      // Conectar filtros em s√©rie
      sourceNode.connect(highPassFilter);
      highPassFilter.connect(notchFilter60Hz);
      notchFilter60Hz.connect(notchFilter50Hz);
      
      console.log(`üéõÔ∏è Cadeia de filtros criada - Threshold: ${this.noiseThreshold}dB`);
      return notchFilter50Hz;
      
    } catch (error) {
      console.error('‚ùå Erro ao criar filtros de ru√≠do:', error);
      logSystem.error(`Erro ao criar filtros de supress√£o de ru√≠do: ${error}`, 'Audio');
      return sourceNode; // Fallback para n√≥ original
    }
  }

  private startAudioAnalysis(): void {
    if (!this.analyser) {
      console.error('‚ùå startAudioAnalysis: analyser n√£o dispon√≠vel');
      logSystem.error('An√°lise de √°udio n√£o pode ser iniciada - analyser indispon√≠vel', 'Audio');
      return;
    }

    const bufferLength = this.analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    let analysisCounter = 0;

    console.log('üéµ Iniciando an√°lise de √°udio em tempo real');
    logSystem.info('An√°lise de √°udio em tempo real iniciada', 'Audio');

    const analyze = () => {
      if (!this.analyser || !this.isRecording) return;

      try {
        this.analyser.getByteFrequencyData(dataArray);
        
        // Calcular n√≠veis de volume em dB usando log10 (corre√ß√£o Manus IA)
        const sum = dataArray.reduce((acc, val) => acc + val, 0);
        const average = sum / bufferLength;
        
        // Calcular dB corretamente
        const dbLevel = average > 0 ? 20 * Math.log10(average / 255) : -Infinity;
        
        // Converter dB para porcentagem para VU Meters (0-100%)
        const leftLevel = Math.max(0, Math.min(100, (dbLevel + 60) * (100 / 60))); // Normalizar -60dB a 0dB para 0-100%
        const rightLevel = Math.max(0, Math.min(100, (dbLevel + 60) * (100 / 60) + Math.random() * 2 - 1)); // Simular stereo
        const peak = leftLevel > 85 || rightLevel > 85;

        // Notificar callbacks VU Meters
        this.volumeCallbacks.forEach(callback => {
          try {
            callback(leftLevel, rightLevel, peak);
          } catch (error) {
            console.error('Erro no callback VU:', error);
          }
        });

        // Log detalhado para debug (a cada 30 execu√ß√µes = ~1 segundo)
        if (analysisCounter % 30 === 0) {
          console.log(`üéµ N√≠vel de √°udio detectado: ${dbLevel.toFixed(1)}dB`);
          console.log(`üéõÔ∏è An√°lise: sum=${sum} avg=${average.toFixed(1)} dB=${dbLevel.toFixed(1)} L=${leftLevel.toFixed(1)}% R=${rightLevel.toFixed(1)}% callbacks=${this.volumeCallbacks.length}/${this.spectrumCallbacks.length}`);
          logSystem.info(`An√°lise Audio: sum=${sum} avg=${average.toFixed(1)} dB=${dbLevel.toFixed(1)} L=${leftLevel.toFixed(1)}% R=${rightLevel.toFixed(1)}% hasSignal=${this.hasSignal} callbacks=${this.volumeCallbacks.length}/${this.spectrumCallbacks.length}`, 'AudioAnalysis');
        }
        analysisCounter++;

        // Marcar que h√° sinal com threshold mais baixo para melhor sensibilidade
        this.hasSignal = this.isRecording && (average > 0.1 || leftLevel > 0.5 || rightLevel > 0.5);
        
        // Sempre notificar callbacks quando est√° gravando, mesmo com sinal baixo
        if (this.isRecording) {
          // Notificar callbacks de volume
          if (this.volumeCallbacks.length > 0) {
            this.volumeCallbacks.forEach(callback => {
              callback(leftLevel, rightLevel, peak);
            });
          } else if (analysisCounter % 120 === 0) {
            console.warn('‚ö†Ô∏è Nenhum callback para VU Meters registrado');
          }

          // Processar dados para spectrum analyzer com FFT (corre√ß√£o Manus IA)
          const spectrumData = new Array(32).fill(0);
          const binSize = Math.floor(dataArray.length / 32);
          
          for (let i = 0; i < 32; i++) {
            let sum = 0;
            for (let j = 0; j < binSize; j++) {
              sum += dataArray[i * binSize + j];
            }
            spectrumData[i] = Math.min(100, (sum / binSize / 255) * 100);
          }
          
          // Log dados de espectro para debug (menos frequente)
          if (analysisCounter % 90 === 0) {
            console.log('üìä Dados de espectro:', spectrumData.slice(0, 5));
          }
          
          // Notificar callbacks de espectro
          if (this.spectrumCallbacks.length > 0) {
            this.spectrumCallbacks.forEach(callback => {
              callback(spectrumData);
            });
          } else if (analysisCounter % 120 === 0) {
            console.warn('‚ö†Ô∏è Nenhum callback para Spectrum Analyzer registrado');
          }
        }

        requestAnimationFrame(analyze);
      } catch (error) {
        console.error('‚ùå Erro durante an√°lise de √°udio:', error);
        logSystem.error(`Erro durante an√°lise de √°udio: ${error}`, 'Audio');
      }
    };

    console.log('üîÑ Iniciando loop de an√°lise de √°udio em tempo real');
    analyze();
  }

  private cleanupAudioAnalysis(): void {
    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }
    this.analyser = null;
  }

  // Callbacks para UI
  onVolumeUpdate(callback: (left: number, right: number, peak: boolean) => void): void {
    this.volumeCallbacks.push(callback);
    console.log(`üìä Callback VU Meters registrado. Total: ${this.volumeCallbacks.length}`);
    logSystem.info(`Callback VU Meters registrado. Total: ${this.volumeCallbacks.length}`, 'Audio');
  }

  onSpectrumUpdate(callback: (data: number[]) => void): void {
    this.spectrumCallbacks.push(callback);
    console.log(`üìà Callback Spectrum registrado. Total: ${this.spectrumCallbacks.length}`);
    logSystem.info(`Callback Spectrum registrado. Total: ${this.spectrumCallbacks.length}`, 'Audio');
  }

  removeVolumeCallback(callback: (left: number, right: number, peak: boolean) => void): void {
    const index = this.volumeCallbacks.indexOf(callback);
    if (index > -1) {
      this.volumeCallbacks.splice(index, 1);
      console.log(`üìä Callback VU Meters removido. Total: ${this.volumeCallbacks.length}`);
    }
  }

  removeSpectrumCallback(callback: (data: number[]) => void): void {
    const index = this.spectrumCallbacks.indexOf(callback);
    if (index > -1) {
      this.spectrumCallbacks.splice(index, 1);
      console.log(`üìà Callback Spectrum removido. Total: ${this.spectrumCallbacks.length}`);
    }
  }

  isPausedState(): boolean {
    return this.isPaused;
  }

  // Configura√ß√µes de formato de nome
  setFileNameFormat(format: string): void {
    this.fileNameFormat = format;
  }

  getFileNameFormat(): string {
    return this.fileNameFormat;
  }

  // M√©todo para verificar se h√° sinal de √°udio
  hasAudioSignal(): boolean {
    return this.isRecording && this.analyser !== null;
  }
   
  // For√ßar inicializa√ß√£o da an√°lise de √°udio para componentes
  forceAudioAnalysisStart(): void {
    if (this.isRecording && this.audioContext && this.analyser) {
      console.log('üéµ For√ßando in√≠cio da an√°lise de √°udio para VU Meters e Spectrum');
      this.hasSignal = true;
      
      // Inicializar componentes com dados vazios para ativar a interface
      this.volumeCallbacks.forEach(callback => {
        callback(0, 0, false);
      });
      this.spectrumCallbacks.forEach(callback => {
        callback(Array(32).fill(0));
      });
      
      console.log('‚úÖ VU Meters e Spectrum inicializados');
    }
  }

  // Configura√ß√µes de MP3 Bitrate
  setMp3Bitrate(bitrate: number): void {
    this.mp3Bitrate = bitrate;
  }

  getMp3Bitrate(): number {
    return this.mp3Bitrate;
  }

  // M√âTODO CORRIGIDO: setNoiseSuppressionEnabled
  setNoiseSuppressionEnabled(enabled: boolean): void {
    this.noiseSuppressionEnabled = enabled;
    this.saveSettings();
    
    // CR√çTICO: Reiniciar monitoramento com nova configura√ß√£o
    this.restartMonitoring();
    
    console.log(`üéõÔ∏è Supress√£o de ru√≠do: ${enabled ? 'ATIVADA' : 'DESATIVADA'}`);
    
    // Log para aba de logs
    logSystem.info(`Supress√£o de ru√≠do ${enabled ? 'ativada' : 'desativada'}`, 'Audio');
  }

  getNoiseSuppressionEnabled(): boolean {
    return this.noiseSuppressionEnabled;
  }

  setNoiseThreshold(threshold: number): void {
    this.noiseThreshold = threshold;
    console.log(`Threshold de ru√≠do ajustado para: ${threshold}dB`);
    logSystem.info(`Threshold de ru√≠do ajustado para: ${threshold}dB`, 'Audio');
  }

  getNoiseThreshold(): number {
    return this.noiseThreshold;
  }

  setNoiseGateAttack(attack: number): void {
    this.noiseGateAttack = attack;
  }

  getNoiseGateAttack(): number {
    return this.noiseGateAttack;
  }

  setNoiseGateRelease(release: number): void {
    this.noiseGateRelease = release;
  }

  getNoiseGateRelease(): number {
    return this.noiseGateRelease;
  }

  // NOVO: Sistema de monitoramento independente para VU Meters sempre ativo
  private async initializeMonitoring(): Promise<void> {
    try {
      console.log('üéØ Inicializando sistema de monitoramento independente...');
      // CR√çTICO: Limpar contextos antes de inicializar
      await this.cleanupAllAudioContexts();
      await this.startMonitoring();
    } catch (error) {
      console.error('‚ùå Erro ao inicializar monitoramento:', error);
      logSystem.error(`Erro ao inicializar monitoramento: ${error}`, 'Audio');
    }
  }

  // NOVO M√âTODO: Limpeza completa de contextos
  private async cleanupAllAudioContexts(): Promise<void> {
    // Parar todas as tracks do stream de monitoramento
    if (this.monitoringStream) {
      this.monitoringStream.getTracks().forEach(track => {
        track.stop();
        console.log('üõë Track de monitoramento parada');
      });
      this.monitoringStream = null;
    }
    
    // Fechar contexto de monitoramento
    if (this.monitoringContext && this.monitoringContext.state !== 'closed') {
      await this.monitoringContext.close();
      this.monitoringContext = null;
      console.log('üõë Contexto de monitoramento fechado');
    }
    
    // Fechar contexto de grava√ß√£o se existir
    if (this.audioContext && this.audioContext.state !== 'closed') {
      await this.audioContext.close();
      this.audioContext = null;
      console.log('üõë Contexto de grava√ß√£o fechado');
    }
    
    this.monitoringAnalyser = null;
    this.analyser = null;
    
    console.log('‚úÖ Todos os contextos de √°udio limpos');
  }

  private async startMonitoring(): Promise<void> {
    try {
      // CR√çTICO: Limpar TODOS os contextos antes de inicializar
      await this.cleanupAllAudioContexts();
      
      const constraints: MediaStreamConstraints = {
        audio: {
          deviceId: this.inputDevice ? { exact: this.inputDevice } : undefined,
          echoCancellation: this.noiseSuppressionEnabled,
          noiseSuppression: this.noiseSuppressionEnabled,
          autoGainControl: this.noiseSuppressionEnabled,
          channelCount: 1, // FOR√áAR MONO para evitar mixagem
          sampleRate: 44100 // Padr√£o profissional
        }
      };

      // USAR MESMO STREAM para monitoramento E grava√ß√£o
      this.monitoringStream = await navigator.mediaDevices.getUserMedia(constraints);
      
      // Configurar contexto de √°udio
      this.monitoringContext = new AudioContext({ sampleRate: 44100 });
      const source = this.monitoringContext.createMediaStreamSource(this.monitoringStream);
      
      this.monitoringAnalyser = this.monitoringContext.createAnalyser();
      this.monitoringAnalyser.fftSize = 512; // Reduzido para melhor performance
      this.monitoringAnalyser.smoothingTimeConstant = 0.3;
      
      source.connect(this.monitoringAnalyser);
      
      this.startContinuousAnalysis();
      
      console.log('‚úÖ Sistema de monitoramento iniciado com fonte √∫nica');
      console.log(`üéØ Dispositivo: ${this.inputDevice || 'padr√£o'}`);
      console.log(`üéõÔ∏è Supress√£o: ${this.noiseSuppressionEnabled ? 'ON' : 'OFF'}`);
      logSystem.info(`Monitoramento iniciado - Dispositivo: ${this.inputDevice || 'padr√£o'}, Supress√£o: ${this.noiseSuppressionEnabled ? 'ON' : 'OFF'}`, 'Audio');
      
    } catch (error) {
      console.error('‚ùå Erro ao inicializar monitoramento:', error);
      logSystem.error(`Erro ao inicializar monitoramento: ${error}`, 'Audio');
      
      // Fallback: tentar com dispositivo padr√£o
      if (this.inputDevice !== 'default') {
        console.log('üîÑ Tentando com dispositivo padr√£o...');
        this.inputDevice = 'default';
        try {
          await this.startMonitoring();
        } catch (fallbackError) {
          console.error('‚ùå Erro no fallback:', fallbackError);
          logSystem.error(`Erro no fallback de dispositivo: ${fallbackError}`, 'Audio');
        }
      }
    }
  }

  // M√âTODO CORRIGIDO: startContinuousAnalysis
  private startContinuousAnalysis(): void {
    if (!this.monitoringAnalyser) return;

    const bufferLength = this.monitoringAnalyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    let analysisCounter = 0;

    const analyze = () => {
      if (!this.monitoringAnalyser || !this.monitoringContext) return;

      try {
        this.monitoringAnalyser.getByteFrequencyData(dataArray);
        
        // Calcular RMS para VU meters
        let sum = 0;
        for (let i = 0; i < bufferLength; i++) {
          const normalized = dataArray[i] / 255.0;
          sum += normalized * normalized;
        }
        
        const rms = Math.sqrt(sum / bufferLength);
        
        // CORRE√á√ÉO: Escala dB profissional (-60dB a 0dB)
        const dbLevel = rms > 0 ? Math.max(20 * Math.log10(rms), -60) : -60;
        
        // Simular stereo para compatibilidade
        const leftLevel = dbLevel;
        const rightLevel = dbLevel;
        
        // Detectar peaks (pr√≥ximo a 0dB)
        const peak = dbLevel > -6;

        // Notificar callbacks para VU meters
        this.volumeCallbacks.forEach(callback => {
          try {
            callback(leftLevel, rightLevel, peak);
          } catch (error) {
            console.error('‚ùå Erro no callback VU:', error);
          }
        });

        // Processar dados para spectrum analyzer com FFT
        const spectrumData = new Array(32).fill(0);
        const binSize = Math.floor(dataArray.length / 32);
        
        for (let i = 0; i < 32; i++) {
          let sum = 0;
          for (let j = 0; j < binSize; j++) {
            sum += dataArray[i * binSize + j];
          }
          spectrumData[i] = Math.min(100, (sum / binSize / 255) * 100);
        }
        
        // Notificar callbacks para spectrum analyzer
        this.spectrumCallbacks.forEach(callback => {
          try {
            callback(spectrumData);
          } catch (error) {
            console.error('‚ùå Erro no callback spectrum:', error);
          }
        });

        // Logs com escala correta
        if (analysisCounter % 60 === 0) {
          console.log(`üéõÔ∏è An√°lise CORRIGIDA: L=${leftLevel.toFixed(1)}dB R=${rightLevel.toFixed(1)}dB`);
        }
        analysisCounter++;

        // Continuar an√°lise
        if (this.monitoringContext && this.monitoringContext.state === 'running') {
          requestAnimationFrame(analyze);
        }
        
      } catch (error) {
        console.error('‚ùå Erro durante an√°lise de √°udio:', error);
        logSystem.error(`Erro durante an√°lise de √°udio: ${error}`, 'Audio');
        // Tentar reiniciar ap√≥s erro
        setTimeout(() => {
          if (this.monitoringAnalyser) {
            analyze();
          }
        }, 1000);
      }
    };

    console.log('üîÑ Iniciando loop de an√°lise de √°udio em tempo real');
    analyze();
  }

  private stopMonitoring(): void {
    if (this.monitoringStream) {
      this.monitoringStream.getTracks().forEach(track => track.stop());
      this.monitoringStream = null;
    }
    
    if (this.monitoringContext) {
      this.monitoringContext.close();
      this.monitoringContext = null;
    }
    
    this.monitoringAnalyser = null;
    console.log('üõë Sistema de monitoramento parado');
  }

  // M√âTODO CORRIGIDO: restartMonitoring
  private async restartMonitoring(): Promise<void> {
    console.log('üîÑ Reiniciando monitoramento...');
    
    // CR√çTICO: Limpar recursos antes de reiniciar
    await this.cleanupAllAudioContexts();
    
    // Aguardar um momento para garantir limpeza
    await new Promise(resolve => setTimeout(resolve, 100));
    
    // Reinicializar
    await this.startMonitoring();
  }
}

export const audioService = new ElectronAudioService();
