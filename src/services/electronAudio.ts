
import { toast } from "sonner";
import { logSystem } from '@/utils/logSystem';

// Interface para funcionalidades de √°udio nativas no Electron
export class ElectronAudioService {
  private mediaRecorder: MediaRecorder | null = null;
  private audioChunks: Blob[] = [];
  private isRecording = false;
  private isPaused = false;
  private outputPath = '';
  private inputDevice = 'default';
  private outputFormat = 'wav';
  private mp3Bitrate = 320;
  private sampleRate = 44100;
  private splitEnabled = false;
  private splitIntervalMinutes = 5;
  private dateFolderEnabled = false;
  private dateFolderFormat = 'dd-mm';
  private fileNameFormat = 'timestamp';
  private recordingStartTime = 0;
  private currentSplitNumber = 1;
  private audioContext: AudioContext | null = null;
  private analyser: AnalyserNode | null = null;
  private noiseGateNode: AudioWorkletNode | null = null;
  private volumeCallbacks: ((left: number, right: number, peak: boolean) => void)[] = [];
  private spectrumCallbacks: ((data: number[]) => void)[] = [];
  private hasSignal = false;
  
  // Configura√ß√µes do Noise Gate
  private noiseSuppressionEnabled = false;
  private noiseThreshold = -35; // dB
  private noiseGateAttack = 50; // ms
  private noiseGateRelease = 200; // ms

  constructor() {
    this.loadSettings();
  }

  private loadSettings() {
    const settings = localStorage.getItem('audioSettings');
    if (settings) {
      const parsed = JSON.parse(settings);
      this.outputFormat = parsed.outputFormat || 'wav';
      this.mp3Bitrate = parsed.mp3Bitrate || 320;
      this.splitEnabled = parsed.splitEnabled || false;
      this.splitIntervalMinutes = parsed.splitIntervalMinutes || 5;
      this.dateFolderEnabled = parsed.dateFolderEnabled || false;
      this.dateFolderFormat = parsed.dateFolderFormat || 'dd-mm';
      this.fileNameFormat = parsed.fileNameFormat || 'timestamp';
      this.noiseSuppressionEnabled = parsed.noiseSuppressionEnabled || false;
      this.noiseThreshold = parsed.noiseThreshold || -35;
      this.noiseGateAttack = parsed.noiseGateAttack || 50;
      this.noiseGateRelease = parsed.noiseGateRelease || 200;
      
      console.log('üìã Configura√ß√µes carregadas:', {
        dateFolderEnabled: this.dateFolderEnabled,
        dateFolderFormat: this.dateFolderFormat,
        splitEnabled: this.splitEnabled,
        fileNameFormat: this.fileNameFormat
      });
    }
  }

  saveSettings() {
    const settings = {
      outputFormat: this.outputFormat,
      mp3Bitrate: this.mp3Bitrate,
      splitEnabled: this.splitEnabled,
      splitIntervalMinutes: this.splitIntervalMinutes,
      dateFolderEnabled: this.dateFolderEnabled,
      dateFolderFormat: this.dateFolderFormat,
      fileNameFormat: this.fileNameFormat,
      noiseSuppressionEnabled: this.noiseSuppressionEnabled,
      noiseThreshold: this.noiseThreshold,
      noiseGateAttack: this.noiseGateAttack,
      noiseGateRelease: this.noiseGateRelease
    };
    localStorage.setItem('audioSettings', JSON.stringify(settings));
  }

  async requestMicrophonePermission(): Promise<boolean> {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100,
          channelCount: 2
        } 
      });
      stream.getTracks().forEach(track => track.stop());
      return true;
    } catch (error) {
      console.error('Erro ao solicitar permiss√£o do microfone:', error);
      toast.error('Erro ao acessar o microfone. Verifique as permiss√µes.');
      return false;
    }
  }

  async startRecording(outputPath: string): Promise<boolean> {
    try {
      if (this.isRecording) {
        toast.warning('Grava√ß√£o j√° est√° em andamento');
        return false;
      }

      // Carregar configura√ß√µes mais recentes antes de iniciar
      this.loadSettings();

      this.recordingStartTime = Date.now();
      this.currentSplitNumber = 1;

      // Criar pasta com data se habilitado
      let finalOutputPath = outputPath;
      if (this.dateFolderEnabled) {
        const dateFolder = this.formatDateFolder();
        // Remover barras duplas e normalizar o path
        const normalizedPath = outputPath.replace(/[\\\/]+$/, '');
        finalOutputPath = `${normalizedPath}\\${dateFolder}`;
        
        console.log(`Pasta por data habilitada. Pasta base: ${normalizedPath}`);
        console.log(`Formato de data: ${this.dateFolderFormat}`);
        console.log(`Pasta de data criada: ${dateFolder}`);
        console.log(`Caminho final: ${finalOutputPath}`);
        
        await this.ensureDirectoryExists(finalOutputPath);
      } else {
        console.log(`Pasta por data desabilitada. Usando pasta base: ${outputPath}`);
        await this.ensureDirectoryExists(outputPath);
        finalOutputPath = outputPath;
      }

      this.outputPath = finalOutputPath;
      console.log(`Grava√ß√£o ser√° salva em: ${this.outputPath}`);

      const hasPermission = await this.requestMicrophonePermission();
      if (!hasPermission) return false;

      console.log('üé§ INICIANDO GRAVA√á√ÉO');
      console.log('üìä Configura√ß√µes de √°udio:', {
        echoCancellation: false,
        noiseSuppression: false,
        autoGainControl: false,
        sampleRate: 44100,
        channelCount: 2,
        inputDevice: this.inputDevice
      });
      console.log('üîä Dispositivo selecionado:', this.inputDevice);

      const constraints: MediaStreamConstraints = {
        audio: {
          sampleRate: 44100,
          channelCount: 2,
          deviceId: this.inputDevice !== 'default' ? { exact: this.inputDevice } : undefined
        }
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);

      // Configurar an√°lise de √°udio
      this.setupAudioAnalysis(stream);

      // Usar formato de alta qualidade sem compress√£o desnecess√°ria
      let mimeType = 'audio/webm;codecs=opus';
      
      // Verificar suporte e usar melhor op√ß√£o dispon√≠vel
      if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
        mimeType = 'audio/webm;codecs=opus';
      } else if (MediaRecorder.isTypeSupported('audio/webm')) {
        mimeType = 'audio/webm';
      } else {
        mimeType = 'audio/mp4';
      }
      
      console.log(`Usando MIME type: ${mimeType} para formato: ${this.outputFormat}`);
      
      const mediaRecorderOptions: MediaRecorderOptions = {
        mimeType: mimeType,
        audioBitsPerSecond: this.mp3Bitrate * 1000
      };
      
      this.mediaRecorder = new MediaRecorder(stream, mediaRecorderOptions);

      this.audioChunks = [];
      this.outputPath = finalOutputPath;

      this.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          this.audioChunks.push(event.data);
        }
      };

      this.mediaRecorder.onstop = () => {
        this.saveRecording();
      };

      this.mediaRecorder.start(1000); // Capturar dados a cada segundo
      this.isRecording = true;
      this.isPaused = false;
      
      console.log('üìà VU Callbacks registrados:', this.volumeCallbacks.length);
      console.log('üìä Spectrum Callbacks registrados:', this.spectrumCallbacks.length);

      // Inicializar sinal de √°udio ap√≥s um pequeno delay
      setTimeout(() => {
        this.forceAudioAnalysisStart();
        console.log('üéµ An√°lise de √°udio iniciada - VU Meters e Spectrum devem estar funcionando');
      }, 500);

      // Configurar split autom√°tico se habilitado
      if (this.splitEnabled) {
        this.scheduleSplit();
      }

      console.log('Grava√ß√£o iniciada - Sistema de buffer otimizado ativo');
      toast.success('Grava√ß√£o iniciada com sucesso');
      return true;

    } catch (error) {
      console.error('Erro ao iniciar grava√ß√£o:', error);
      toast.error('Erro ao iniciar grava√ß√£o');
      return false;
    }
  }

  stopRecording(): void {
    if (this.mediaRecorder && this.isRecording) {
      this.mediaRecorder.stop();
      this.mediaRecorder.stream.getTracks().forEach(track => track.stop());
      this.isRecording = false;
      this.isPaused = false;
      this.currentSplitNumber = 1;
      
      // Limpar contexto de √°udio
      this.cleanupAudioAnalysis();
      
      console.log('Grava√ß√£o finalizada');
      toast.success('Grava√ß√£o finalizada');
    }
  }

  pauseRecording(): void {
    if (this.mediaRecorder && this.isRecording) {
      if (this.mediaRecorder.state === 'recording') {
        this.mediaRecorder.pause();
        this.isPaused = true;
        console.log('Grava√ß√£o pausada');
        toast.info('Grava√ß√£o pausada');
      } else if (this.mediaRecorder.state === 'paused') {
        this.mediaRecorder.resume();
        this.isPaused = false;
        console.log('Grava√ß√£o retomada');
        toast.info('Grava√ß√£o retomada');
      }
    }
  }

  private async saveRecording(): Promise<void> {
    try {
      const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
      const arrayBuffer = await audioBlob.arrayBuffer();
      const uint8Array = new Uint8Array(arrayBuffer);

      // Se estiver no Electron, usar a API nativa para salvar
      if (window.electronAPI) {
        const filename = this.formatFileName();

        // Garantir que estamos usando o outputPath correto (j√° inclui a subpasta se habilitada)
        console.log(`Salvando arquivo em: ${this.outputPath}`);
        console.log(`Nome do arquivo: ${filename}`);
        
        // Normalizar path e garantir que o arquivo seja salvo no diret√≥rio correto
        const normalizedPath = this.outputPath.replace(/[\\\/]+$/, '');
        const fullPath = `${normalizedPath}\\${filename}`;
        
        console.log(`Caminho completo do arquivo: ${fullPath}`);

        try {
          await window.electronAPI.saveAudioFile(fullPath, uint8Array);
          console.log(`‚úÖ Arquivo salvo com sucesso em: ${fullPath}`);
          toast.success(`Arquivo salvo: ${filename}`);
        } catch (error) {
          console.error('‚ùå Erro ao salvar via Electron API:', error);
          // Fallback para download
          this.downloadAudioFile(audioBlob, filename);
        }
      } else {
        // Fallback para download no navegador
        const extension = this.outputFormat === 'wav' ? 'wav' : 
                         this.outputFormat === 'mp3' ? 'mp3' : 'webm';
        const filename = `gravacao_${Date.now()}.${extension}`;
        this.downloadAudioFile(audioBlob, filename);
      }

    } catch (error) {
      console.error('Erro ao salvar grava√ß√£o:', error);
      toast.error('Erro ao salvar arquivo de √°udio');
    }
  }

  private downloadAudioFile(blob: Blob, filename: string): void {
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = filename;
    a.click();
    URL.revokeObjectURL(url);
    toast.success(`Download iniciado: ${filename}`);
  }

  isCurrentlyRecording(): boolean {
    return this.isRecording;
  }

  getRecordingState(): string {
    if (!this.mediaRecorder) return 'stopped';
    return this.mediaRecorder.state;
  }

  async getAudioDevices(): Promise<MediaDeviceInfo[]> {
    try {
      const devices = await navigator.mediaDevices.enumerateDevices();
      return devices.filter(device => device.kind === 'audioinput');
    } catch (error) {
      console.error('Erro ao obter dispositivos de √°udio:', error);
      return [];
    }
  }

  setInputDevice(deviceId: string): void {
    this.inputDevice = deviceId;
  }

  setOutputFormat(format: string): void {
    this.outputFormat = format;
  }

  setSampleRate(rate: number): void {
    this.sampleRate = rate;
  }

  async ensureDirectoryExists(dirPath: string): Promise<void> {
    try {
      console.log(`üîç Verificando diret√≥rio: ${dirPath}`);
      if (window.electronAPI) {
        await window.electronAPI.ensureDirectory(dirPath);
        console.log(`‚úÖ Diret√≥rio criado/verificado: ${dirPath}`);
      } else {
        // No navegador, apenas logar
        console.log('‚ö†Ô∏è Modo navegador - diret√≥rios n√£o podem ser criados automaticamente');
      }
    } catch (error) {
      console.error('‚ùå Erro ao verificar/criar diret√≥rio:', error);
      toast.error(`Erro ao criar pasta: ${dirPath}`);
      throw error;
    }
  }

  getInputDevice(): string {
    return this.inputDevice;
  }

  getOutputFormat(): string {
    return this.outputFormat;
  }

  getSampleRate(): number {
    return this.sampleRate;
  }

  // Configura√ß√µes de split
  setSplitEnabled(enabled: boolean): void {
    this.splitEnabled = enabled;
  }

  setSplitInterval(minutes: number): void {
    this.splitIntervalMinutes = minutes;
  }

  getSplitEnabled(): boolean {
    return this.splitEnabled;
  }

  getSplitInterval(): number {
    return this.splitIntervalMinutes;
  }

  // Configura√ß√µes de pasta por data
  setDateFolderEnabled(enabled: boolean): void {
    this.dateFolderEnabled = enabled;
  }

  setDateFolderFormat(format: string): void {
    this.dateFolderFormat = format;
  }

  getDateFolderEnabled(): boolean {
    return this.dateFolderEnabled;
  }

  getDateFolderFormat(): string {
    return this.dateFolderFormat;
  }

  private formatDateFolder(): string {
    const now = new Date();
    const day = now.getDate().toString().padStart(2, '0');
    const month = (now.getMonth() + 1).toString().padStart(2, '0');
    const year = now.getFullYear().toString();

    switch (this.dateFolderFormat) {
      case 'dd-mm':
        return `${day}-${month}`;
      case 'dd-mm-yyyy':
        return `${day}-${month}-${year}`;
      case 'mm-dd-yyyy':
        return `${month}-${day}-${year}`;
      case 'yyyy-mm-dd':
        return `${year}-${month}-${day}`;
      case 'yyyy/mm/dd':
        return `${year}/${month}/${day}`;
      default:
        return `${day}-${month}`;
    }
  }

  private formatFileName(): string {
    const now = new Date();
    const day = now.getDate().toString().padStart(2, '0');
    const month = (now.getMonth() + 1).toString().padStart(2, '0');
    const year = now.getFullYear().toString();
    const hours = now.getHours().toString().padStart(2, '0');
    const minutes = now.getMinutes().toString().padStart(2, '0');
    const seconds = now.getSeconds().toString().padStart(2, '0');

    const extension = this.outputFormat === 'wav' ? 'wav' : 
                     this.outputFormat === 'mp3' ? 'mp3' : 'webm';

    let baseName: string;
    switch (this.fileNameFormat) {
      case 'hh-mm-ss-seq':
        baseName = `${hours}-${minutes}-${seconds}-${this.currentSplitNumber.toString().padStart(3, '0')}`;
        break;
      case 'dd-mm-hh-mm-ss-seq':
        baseName = `${day}-${month}-${hours}-${minutes}-${seconds}-${this.currentSplitNumber.toString().padStart(3, '0')}`;
        break;
      case 'timestamp':
      default:
        const timestamp = now.toISOString().replace(/[:.]/g, '-').slice(0, 19);
        baseName = this.splitEnabled && this.currentSplitNumber > 1 
          ? `gravacao_${timestamp}_parte${this.currentSplitNumber}`
          : `gravacao_${timestamp}`;
        break;
    }

    return `${baseName}.${extension}`;
  }

  private scheduleSplit(): void {
    setTimeout(() => {
      if (this.isRecording && this.splitEnabled) {
        this.performSplit();
      }
    }, this.splitIntervalMinutes * 60 * 1000);
  }

  private async performSplit(): Promise<void> {
    if (!this.isRecording || !this.mediaRecorder) return;

    try {
      // Parar grava√ß√£o atual
      this.mediaRecorder.stop();
      
      // Aguardar um breve momento para processamento
      await new Promise(resolve => setTimeout(resolve, 500));
      
      // Incrementar n√∫mero da parte
      this.currentSplitNumber++;
      
      // Reiniciar grava√ß√£o com novo arquivo
      this.audioChunks = [];
      const stream = this.mediaRecorder.stream;
      
      // Recriar MediaRecorder
      this.mediaRecorder = new MediaRecorder(stream, {
        mimeType: this.mediaRecorder.mimeType
      });

      this.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          this.audioChunks.push(event.data);
        }
      };

      this.mediaRecorder.onstop = () => {
        this.saveRecording();
      };

      this.mediaRecorder.start(1000);
      
      // Agendar pr√≥ximo split
      this.scheduleSplit();
      
      toast.info(`Iniciando parte ${this.currentSplitNumber} da grava√ß√£o`);
    } catch (error) {
      console.error('Erro ao fazer split:', error);
      toast.error('Erro ao dividir arquivo');
    }
  }

  // An√°lise de √°udio em tempo real
  private setupAudioAnalysis(stream: MediaStream): void {
    try {
      this.audioContext = new AudioContext({ sampleRate: 44100 });
      const source = this.audioContext.createMediaStreamSource(stream);
      
      this.analyser = this.audioContext.createAnalyser();
      this.analyser.fftSize = 2048;
      this.analyser.smoothingTimeConstant = 0.3;
      
      // N√ÉO conectar ao destination para evitar feedback
      source.connect(this.analyser);
      
      console.log('üé§ Contexto de √°udio configurado para an√°lise em tempo real');
      console.log('üìä Configura√ß√µes AudioContext:', {
        sampleRate: this.audioContext.sampleRate,
        fftSize: this.analyser.fftSize,
        frequencyBinCount: this.analyser.frequencyBinCount
      });
      this.startAudioAnalysis();
    } catch (error) {
      console.error('‚ùå Erro ao configurar an√°lise de √°udio:', error);
      logSystem.error(`Erro ao configurar an√°lise de √°udio: ${error}`, 'Audio');
    }
  }

  private createNoiseProcessingChain(audioContext: AudioContext, sourceNode: AudioNode): AudioNode {
    try {
      // Filtro High-Pass para remover ru√≠do de baixa frequ√™ncia
      const highPassFilter = audioContext.createBiquadFilter();
      highPassFilter.type = 'highpass';
      highPassFilter.frequency.setValueAtTime(80, audioContext.currentTime);
      highPassFilter.Q.setValueAtTime(1, audioContext.currentTime);
      
      // Filtro Notch para remover ru√≠do el√©trico de 60Hz
      const notchFilter60Hz = audioContext.createBiquadFilter();
      notchFilter60Hz.type = 'notch';
      notchFilter60Hz.frequency.setValueAtTime(60, audioContext.currentTime);
      notchFilter60Hz.Q.setValueAtTime(10, audioContext.currentTime);
      
      // Filtro Notch para remover ru√≠do el√©trico de 50Hz (Europa)
      const notchFilter50Hz = audioContext.createBiquadFilter();
      notchFilter50Hz.type = 'notch';
      notchFilter50Hz.frequency.setValueAtTime(50, audioContext.currentTime);
      notchFilter50Hz.Q.setValueAtTime(10, audioContext.currentTime);
      
      // Conectar filtros em s√©rie
      sourceNode.connect(highPassFilter);
      highPassFilter.connect(notchFilter60Hz);
      notchFilter60Hz.connect(notchFilter50Hz);
      
      console.log(`üéõÔ∏è Cadeia de filtros criada - Threshold: ${this.noiseThreshold}dB`);
      return notchFilter50Hz;
      
    } catch (error) {
      console.error('‚ùå Erro ao criar filtros de ru√≠do:', error);
      logSystem.error(`Erro ao criar filtros de supress√£o de ru√≠do: ${error}`, 'Audio');
      return sourceNode; // Fallback para n√≥ original
    }
  }

  private startAudioAnalysis(): void {
    if (!this.analyser) {
      console.error('‚ùå startAudioAnalysis: analyser n√£o dispon√≠vel');
      logSystem.error('An√°lise de √°udio n√£o pode ser iniciada - analyser indispon√≠vel', 'Audio');
      return;
    }

    const bufferLength = this.analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    let analysisCounter = 0;

    console.log('üéµ Iniciando an√°lise de √°udio em tempo real');
    logSystem.info('An√°lise de √°udio em tempo real iniciada', 'Audio');

    const analyze = () => {
      if (!this.analyser || !this.isRecording) return;

      try {
        this.analyser.getByteFrequencyData(dataArray);
        
        // Calcular n√≠veis de volume em dB usando log10 (corre√ß√£o Manus IA)
        const sum = dataArray.reduce((acc, val) => acc + val, 0);
        const average = sum / bufferLength;
        
        // Calcular dB corretamente
        const dbLevel = average > 0 ? 20 * Math.log10(average / 255) : -Infinity;
        
        // Converter dB para porcentagem para VU Meters (0-100%)
        const leftLevel = Math.max(0, Math.min(100, (dbLevel + 60) * (100 / 60))); // Normalizar -60dB a 0dB para 0-100%
        const rightLevel = Math.max(0, Math.min(100, (dbLevel + 60) * (100 / 60) + Math.random() * 2 - 1)); // Simular stereo
        const peak = leftLevel > 85 || rightLevel > 85;

        // Notificar callbacks VU Meters
        this.volumeCallbacks.forEach(callback => {
          try {
            callback(leftLevel, rightLevel, peak);
          } catch (error) {
            console.error('Erro no callback VU:', error);
          }
        });

        // Log detalhado para debug (a cada 30 execu√ß√µes = ~1 segundo)
        if (analysisCounter % 30 === 0) {
          console.log(`üéµ N√≠vel de √°udio detectado: ${dbLevel.toFixed(1)}dB`);
          console.log(`üéõÔ∏è An√°lise: sum=${sum} avg=${average.toFixed(1)} dB=${dbLevel.toFixed(1)} L=${leftLevel.toFixed(1)}% R=${rightLevel.toFixed(1)}% callbacks=${this.volumeCallbacks.length}/${this.spectrumCallbacks.length}`);
          logSystem.info(`An√°lise Audio: sum=${sum} avg=${average.toFixed(1)} dB=${dbLevel.toFixed(1)} L=${leftLevel.toFixed(1)}% R=${rightLevel.toFixed(1)}% hasSignal=${this.hasSignal} callbacks=${this.volumeCallbacks.length}/${this.spectrumCallbacks.length}`, 'AudioAnalysis');
        }
        analysisCounter++;

        // Marcar que h√° sinal com threshold mais baixo para melhor sensibilidade
        this.hasSignal = this.isRecording && (average > 0.1 || leftLevel > 0.5 || rightLevel > 0.5);
        
        // Sempre notificar callbacks quando est√° gravando, mesmo com sinal baixo
        if (this.isRecording) {
          // Notificar callbacks de volume
          if (this.volumeCallbacks.length > 0) {
            this.volumeCallbacks.forEach(callback => {
              callback(leftLevel, rightLevel, peak);
            });
          } else if (analysisCounter % 120 === 0) {
            console.warn('‚ö†Ô∏è Nenhum callback para VU Meters registrado');
          }

          // Processar dados para spectrum analyzer com FFT (corre√ß√£o Manus IA)
          const spectrumData = new Array(32).fill(0);
          const binSize = Math.floor(dataArray.length / 32);
          
          for (let i = 0; i < 32; i++) {
            let sum = 0;
            for (let j = 0; j < binSize; j++) {
              sum += dataArray[i * binSize + j];
            }
            spectrumData[i] = Math.min(100, (sum / binSize / 255) * 100);
          }
          
          // Log dados de espectro para debug (menos frequente)
          if (analysisCounter % 90 === 0) {
            console.log('üìä Dados de espectro:', spectrumData.slice(0, 5));
          }
          
          // Notificar callbacks de espectro
          if (this.spectrumCallbacks.length > 0) {
            this.spectrumCallbacks.forEach(callback => {
              callback(spectrumData);
            });
          } else if (analysisCounter % 120 === 0) {
            console.warn('‚ö†Ô∏è Nenhum callback para Spectrum Analyzer registrado');
          }
        }

        requestAnimationFrame(analyze);
      } catch (error) {
        console.error('‚ùå Erro durante an√°lise de √°udio:', error);
        logSystem.error(`Erro durante an√°lise de √°udio: ${error}`, 'Audio');
      }
    };

    console.log('üîÑ Iniciando loop de an√°lise de √°udio em tempo real');
    analyze();
  }

  private cleanupAudioAnalysis(): void {
    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }
    this.analyser = null;
  }

  // Callbacks para UI
  onVolumeUpdate(callback: (left: number, right: number, peak: boolean) => void): void {
    this.volumeCallbacks.push(callback);
    console.log(`üìä Callback VU Meters registrado. Total: ${this.volumeCallbacks.length}`);
    logSystem.info(`Callback VU Meters registrado. Total: ${this.volumeCallbacks.length}`, 'Audio');
  }

  onSpectrumUpdate(callback: (data: number[]) => void): void {
    this.spectrumCallbacks.push(callback);
    console.log(`üìà Callback Spectrum registrado. Total: ${this.spectrumCallbacks.length}`);
    logSystem.info(`Callback Spectrum registrado. Total: ${this.spectrumCallbacks.length}`, 'Audio');
  }

  removeVolumeCallback(callback: (left: number, right: number, peak: boolean) => void): void {
    const index = this.volumeCallbacks.indexOf(callback);
    if (index > -1) {
      this.volumeCallbacks.splice(index, 1);
      console.log(`üìä Callback VU Meters removido. Total: ${this.volumeCallbacks.length}`);
    }
  }

  removeSpectrumCallback(callback: (data: number[]) => void): void {
    const index = this.spectrumCallbacks.indexOf(callback);
    if (index > -1) {
      this.spectrumCallbacks.splice(index, 1);
      console.log(`üìà Callback Spectrum removido. Total: ${this.spectrumCallbacks.length}`);
    }
  }

  isPausedState(): boolean {
    return this.isPaused;
  }

  // Configura√ß√µes de formato de nome
  setFileNameFormat(format: string): void {
    this.fileNameFormat = format;
  }

  getFileNameFormat(): string {
    return this.fileNameFormat;
  }

  // M√©todo para verificar se h√° sinal de √°udio
  hasAudioSignal(): boolean {
    return this.isRecording && this.analyser !== null;
  }
   
  // For√ßar inicializa√ß√£o da an√°lise de √°udio para componentes
  forceAudioAnalysisStart(): void {
    if (this.isRecording && this.audioContext && this.analyser) {
      console.log('üéµ For√ßando in√≠cio da an√°lise de √°udio para VU Meters e Spectrum');
      this.hasSignal = true;
      
      // Inicializar componentes com dados vazios para ativar a interface
      this.volumeCallbacks.forEach(callback => {
        callback(0, 0, false);
      });
      this.spectrumCallbacks.forEach(callback => {
        callback(Array(32).fill(0));
      });
      
      console.log('‚úÖ VU Meters e Spectrum inicializados');
    }
  }

  // Configura√ß√µes de MP3 Bitrate
  setMp3Bitrate(bitrate: number): void {
    this.mp3Bitrate = bitrate;
  }

  getMp3Bitrate(): number {
    return this.mp3Bitrate;
  }

  // Configura√ß√µes do Noise Gate
  setNoiseSuppressionEnabled(enabled: boolean): void {
    this.noiseSuppressionEnabled = enabled;
    console.log(`Supress√£o de ru√≠do: ${enabled ? 'habilitada' : 'desabilitada'}`);
    logSystem.info(`Supress√£o de ru√≠do ${enabled ? 'habilitada' : 'desabilitada'}`, 'Audio');
  }

  getNoiseSuppressionEnabled(): boolean {
    return this.noiseSuppressionEnabled;
  }

  setNoiseThreshold(threshold: number): void {
    this.noiseThreshold = threshold;
    console.log(`Threshold de ru√≠do ajustado para: ${threshold}dB`);
    logSystem.info(`Threshold de ru√≠do ajustado para: ${threshold}dB`, 'Audio');
  }

  getNoiseThreshold(): number {
    return this.noiseThreshold;
  }

  setNoiseGateAttack(attack: number): void {
    this.noiseGateAttack = attack;
  }

  getNoiseGateAttack(): number {
    return this.noiseGateAttack;
  }

  setNoiseGateRelease(release: number): void {
    this.noiseGateRelease = release;
  }

  getNoiseGateRelease(): number {
    return this.noiseGateRelease;
  }
}

export const audioService = new ElectronAudioService();
